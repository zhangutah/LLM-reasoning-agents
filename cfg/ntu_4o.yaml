# Configuration file for the NTU project
oss_fuzz_dir: /home/yk/code/oss-fuzz/
save_dir: outputs/models/gpt-4o
cache_dir: /home/yk/code/LLM-reasoning-agents/cache/
model_name: gpt-4o
temperature: 0.7
run_time: 1
max_fix: 5
max_tool_call: 50
usage_token_limit: 1000
model_token_limit: 8096
n_examples: 1
example_mode: random
iterations: 3
num_processes: null # Will be set to os.cpu_count()//2 at runtime
bench_dir: benchmark-sets/ntu
project_name: kamailio
function_signatures: ["parse_diversion_header"]
clear_msg_flag: true
tool_flag: true
method: issta